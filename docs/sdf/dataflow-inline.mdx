---
sidebar_position: 3
title: "Dataflow - Inline Definitions"
description: "Inline Stateful Dataflows"
slug: /sdf/dataflow-inline
---

**Inline Dataflows** allow you to create dataflows with inline code. These dataflows are useful for trying out various features of the product. Deploying an inline dataflow is simple:

1. Download (or create) a dataflow file.
2. Run the dataflow.

While inline dataflows are a breeze to get started with, we recommend using [Composable Dataflows] for more intricate projects.

## The Dataflow

The **dataflow** is the composition compostion file, that combines functions, types and states into services. Each service can perform one or more operations.

#### `dataflow.yaml`

The [SDF] command line tool uses the dataflow definition file `dataflow.yaml` to generate the Webassembly runtime. A dataflow file for inline composition has the following core components:

```yaml
# dataflow.yaml
apiVersion: <version>

meta:
  name: <dataflow-name>
  version: <dataflow-version>
  namespace: <dataflow-namespace>

config:
  converter: <converter-props>
  consumer: <consumer-props>

types:
  <type-name>: <type-props>

topics:
  <topic-name>: <topic-props>

states:
  <state-name>: <state-props>

services:
  <service-name>:
    sources:
      -type: <topic-props>

    states:
      <state-name>: <state-props>

    transforms:
      - operator: <operator-type>
        uses: <imported-function-name>

    sinks:
      - name: <topic-props>
```

The sections are as follows:
* `meta` - metadata about the package
* `config` - short for configurations, holds the default configurations.
* `types` - defines types used in the package
* `topics` - defines topics used in the package
* `states` - defines states used in functions
* `services` - defines the service properties
  * `sources` - defines the source topics used in the service
  * `states` - defines the state properties used in the service
  * `transforms` - defines the list of operators and the imported functions used in the service
  * `sinks` - defines the sink topics used in the service

The dataflow file has other variants such as `window` and `partitions`, which are omitted for simplicity. For additional details checkout the [Dataflow file] section.


#### Create a Dataflow

Let's create a simple dataflow to split a sentence into words and count the words. This is the same example we used in the [Composable Dataflows] section, so you can examine both sections for a comparission.

##### 1. Create the Dataflow file

Ceate a dataflow file in the directory `split-sentence` directory:

%copy%
```bash
$ mkdir -p split-sentence-inline
$ cd split-sentence-inline
```

Create the `dataflow.yaml` and add the following content:

%copy%
```yaml
#dataflow.yanl
apiVersion: 0.4.0

meta:
  name: split-sentence-inline
  version: 0.1.0
  namespace: example

config:
  converter: raw

topics:
  sentence:
    schema:
      value:
        type: string
        converter: raw
  words:
    schema:
      value:
        type: string
        converter: raw

services:
  sentence-words:
    sources:
      - type: topic
        id: sentence

    transforms:
      - operator: flat-map
        run: |
          fn sentence_to_words(sentence: String) -> Result<Vec<String>, String> {
            Ok(sentence.split_whitespace().map(String::from).collect())
          }
      - operator: map
        run: |
          pub fn augment_count(word: String) -> Result<String, String> {
            Ok(format!("{}({})", word, word.chars().count()))
          }

    sinks:
      - type: topic
        id: words
```

##### 2. Run the Dataflow

Use `sdf` command line tool to run the dataflow:

%copy%
```bash
$ sdf run --ui
```

Use `--ui` to generate the graphical representation and run the Studio.

##### 3. Test the Dataflow

1. Produce sentences to in `sentence` topic:

%copy%
```bash
$ fluvio produce sentence
```


```bash
Hello world
Hi there
```

Consume from `words` to retrieve the result:

%copy%
```bash
$ fluvio consume words -Bd
```

```bash
Hello(5)
world(5)
Hi(2)
there(5)
```

##### 4. Show State

The dataflow collects runtime metrics that you can inspect in the runtime terminal.

Check the `sentence-to-words` counters:

%copy first-line%
```bash
>> show state sentence-words/sentence-to-words/metrics --table
 Key    Window  succeeded  failed
 stats  *       2          0
```

Check the `augment-count` counters:

%copy first-line%
```bash
>> show state sentence-words/augment-count/metrics --table
 Key    Window  succeeded  failed
 stats  *       4          0
```

Congratulations! You've successfully built and run a composable dataflow! The project is available for download in [github].

##### 5. Clean-up

Exit `sdf` terminal and remove the topics:

```bash
fluvio topic delete sentence
fluvio topic delete words
```

### References

* <a href="https://github.com/infinyon/stateful-dataflows-examples/" target="_blank">Example Workflows in github</a>

[Composable Dataflows]: /sdf/dataflow-composition
[SDF]: /sdf
